version: '3.8'

services:
  verba:
    build:
      context: ./
      dockerfile: Dockerfile
    ports:
      - 8001:8000
    environment:
      - WEAVIATE_URL_VERBA=http://weaviate:8081
      - OPENAI_API_KEY=$OPENAI_API_KEY
      - COHERE_API_KEY=$COHERE_API_KEY
      - OLLAMA_URL=http://ollama:11434
      - OLLAMA_MODEL=llama2:70b
      - OLLAMA_EMBED_MODEL=$OLLAMA_EMBED_MODEL
      - UNSTRUCTURED_API_KEY=$UNSTRUCTURED_API_KEY
      - UNSTRUCTURED_API_URL=$UNSTRUCTURED_API_URL
      - GITHUB_TOKEN=$GITHUB_TOKEN
    volumes:
      - ./data:/data/
    depends_on:
      weaviate:
        condition: service_healthy
      ollama:
        condition: service_healthy
    healthcheck:
      test: wget --no-verbose --tries=3 --spider http://localhost:8001 || exit 1
      interval: 5s
      timeout: 10s
      retries: 5
      start_period: 10s
    networks:
      - ollama-docker
      - verba-network

  weaviate:
    command:
      - --host
      - 0.0.0.0
      - --port
      - '8081'
      - --scheme
      - http
    image: semitechnologies/weaviate:1.25.10
    ports:
      - 8081:8081
      - 3001:8081
    volumes:
      - weaviate_data:/var/lib/weaviate
    restart: on-failure:0
    healthcheck:
      test: wget --no-verbose --tries=3 --spider http://localhost:8081/v1/.well-known/ready || exit 1
      interval: 5s
      timeout: 10s
      retries: 5
      start_period: 10s
    environment:
      OPENAI_APIKEY: $OPENAI_API_KEY
      COHERE_APIKEY: $COHERE_API_KEY
      QUERY_DEFAULTS_LIMIT: 25
      AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: 'true'
      PERSISTENCE_DATA_PATH: '/var/lib/weaviate'
      ENABLE_MODULES: 'e'
      CLUSTER_HOSTNAME: 'node1'
    networks:
      - verba-network

  ollama:
    container_name: ollama
    image: ollama/ollama:latest
    volumes:
      - ./ollama/ollama:/root/.ollama
    ports:
      - 7869:11434
    environment:
      - OLLAMA_KEEP_ALIVE=24h
    healthcheck:
      test: curl --fail http://localhost:11434/api/tags || exit 1
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s
    restart: unless-stopped
    networks:
      - ollama-docker
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]

  ollama-webui:
    image: ghcr.io/open-webui/open-webui:main
    container_name: ollama-webui
    volumes:
      - ./ollama/ollama-webui:/app/backend/data
    depends_on:
      - ollama
    ports:
      - 8082:8080  # Changed from 8080 to avoid conflict
    environment:
      - OLLAMA_BASE_URLS=http://ollama:11434
      - ENV=dev
      - WEBUI_AUTH=False
      - WEBUI_NAME=Verba AI
      - WEBUI_URL=http://localhost:8082  # Updated to match new port
      - WEBUI_SECRET_KEY=t0p-s3cr3t
    restart: unless-stopped
    networks:
      - ollama-docker

networks:
  ollama-docker:
    external: false
  verba-network:
    external: false

volumes:
  weaviate_data: {}
  ollama_data: {}